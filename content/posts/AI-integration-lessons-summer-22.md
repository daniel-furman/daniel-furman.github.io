---
title: "4 lessons learned applying 'Smart Integration' in AI development."
date: 2022-08-10
katex: true
markup: "mmark"
---

# 4 lessons learned applying 'Smart Integration' in AI development.
---
<br><br>
# **Under Construction**
<br><br>
In April 2022, Silvio Palumbo wrote a <a target="_blank" rel="noopener noreferrer" href="https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614">blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI strategy. It’s tailored to companies that are in the business of applying AI solutions. Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.
<br><br>
As Palumbo puts it, the Smart Integrator finds “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.” 
<br><br>
What differentiates MAMAA/FAANG from the Smart Integrators, one might ask? The "Googles" of the world are primary research players – along with Academia (think UC Berkeley or MIT). They are responsible for developing innovative tools that power AI technologies. Fortuitously, many of these tools are open-sourced (Apache Spark, Airflow, PyTorch, etc.) or productized as services (AWS/Azure/GCP, Databricks, etc.), **ripe for integration in your organization**. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to use. 
<br><br>
In a tooling-enabled world, integrating AI largely comes down to the **communication and execution of the right strategy**. Here are a few lessons I’ve learned applying Smart Integration to develop productized AI solutions.
<br><br>
* **Definitions**: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for certain predictive tasks. These include predicting the next word in a text, recommending friends on a social media platform, recognizing hate speech or misinformation online, translating between languages, etc., the list of use-cases is steadily growing. Here, we will refer to AI and ML interchangeably and synonymously. 
<br><br>
## Lesson 1: On scoping use-cases: Know when AI is right (or wrong) pre-development
---
<br><br>
AI is working well when it's plugged into commercial workstreams and generating value. Machine learning models should be automating tasks, augmenting analyses, surfacing information, or be otherwise actively engaged. If models are sitting idle, you’re not quite there yet. And, frequently, the reason they are sitting idle is that the use-case wasn’t viable in the first place (Cassie K., steps to an AI project).
<br><br>
It thus pays to be methodical when scoping the viability of an AI project. Incorporate all voices across your team. Think slowly about how the tool plugs in given the context. The scoping phase is, in my opinion, where a project is made or broken. Treat it as such.
<br><br>
With the right use-case, integrating AI into a tool that people use (and love) becomes far more straightforward. To facilitate getting on this track, go with options that are more “low-hanging fruit” at first, both in terms of commercial application and technical implementation. You don't want users’ “first awesome experience” to be tarnished by poor-quality predictions. By going with a “low-hanging fruit”, you’re guaranteeing that the model can reach the “product success” threshold without too much fuss. You are therefore free to think diligently about how to best plug in the tool in your commercial setting, the lifeline of true project success. 
<br><br>
Oh, and look for AI solutions that can deliver the most value (sounds obvious, right?). Eyeing the opportunities with **high-value proposition is more important than “cool”**. Does your business do 250 deals of workstream A a year, and an AI tool can deliver greenfield value to each engagement? Oh, and perhaps it can plug it into workstreams B and C as well? Probably a good avenue to pursue development for. It’s certainly a better avenue to pursue compared with a “fancier”  tool that is tailored specifically to workstream D, which occurs less frequently than the other workstreams. Yes, this holds true despite whether or not there’s a difference in the IP value of the underlying machine learning models. In most cases, better to go with a tool that plugs in well across your company’s business. 
<br><br>
## Lesson 2: On ideating solutions: AI and data analytics pair well
---
<br><br>
In lieu of fully automatable workstreams, aim to augment existing analytics with alternative data and machine learning. Data quality over data quantity, most of the time.
<br><br>
## Lesson 3: On team structure: Spread the “multi-disciplinary” mantra to every dimension of your project
---
<br><br>
## Lesson 4: On product development: Focus on great user experiences
---
<br><br>
Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience. Build trusted products
