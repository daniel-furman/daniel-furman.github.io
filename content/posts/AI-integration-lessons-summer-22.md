---
title: "5 lessons learned applying 'Smart Integration' in AI/ML development."
date: 2022-08-10
katex: true
markup: "mmark"
---

# 5 lessons learned applying 'Smart Integration' in AI/ML development.
---
<br><br>
**Under Construction**
<br><br>
In April 2022, Silvio Palumbo wrote a <a target="_blank" rel="noopener noreferrer" href="https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614">blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI/ML** strategy. The playbook is tailored to companies vying to rise to the cream of the crop in the business of applying AI. If you're working on AI applications, the Smart Integration ideas are relavent to you, whether you are a data scientist, business executive, manager, or just about everybody else adjacent. 
<br><br>
* ** Definitions: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for a certain predictive task. Here, we will refer to AI/ML interchangeably and synonymously.  
<br><br>
As Palumbo puts it, the Smart Integrator find “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.” 
<br><br>
Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.
<br><br>
What differentiates MAMAA/FAANG from the Smart Integrators? The Googles of the world – along with Academia (think UC Berkeley or MIT) – represent the primary researchers. They are responsible for developing the innovative tools that power today’s AI technologies. Fortuitously, many of these tools are open-sourced (such as Apache Spark, Airflow, PyTorch) or productized as services (such as AWS, Databricks, Snowflake), ripe for integration in your organization. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to apply in commercial use-cases. 
<br><br>
In a tooling enabled world, integrating AI well in commercial settings laregly comes down to the communication and execution of the right strategy, one with sound “Smart Integration” fundamentals. Here’s a few lessons I’ve learned so far as a data scientist applying these ideas to develop AI/ML products for commercial use-cases. 
<br><br>

## Lesson 1: Prioritize use-cases that deliver value to the most people

---
<br><br>

Scope the commercial value of plugging AI into your commercial context. You don't want to get trapped searching for use-cases where the primary value is  how proprietary the models would be. Google will always beat your organizations model in the end, what's more important for most businesses is finding workstrams that can seamlessly and widely plug into AI, regardless if your model is 87 or 93 percent accurate. Choose those that are poised to have outsized returns , those that are applicable across workstreams and disciplines, and those that are proven to be viable from a technical standpoint.

<br><br>
## Lesson 2: Spread the “multi-disciplinary” mantra to every level of your team
---
<br><br>
## Lesson 3: Evolve in waves with a culture of experimentation
---
<br><br>
## Lesson 4: Build trusted products that people want
---
<br><br>
## Lesson 5: Focus on great user experiences
---
<br><br>
Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience.
<br><br>
