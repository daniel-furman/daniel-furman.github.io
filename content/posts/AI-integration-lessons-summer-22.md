---
title: "5 lessons learned applying 'Smart Integration' in AI/ML development."
date: 2022-08-10
katex: true
markup: "mmark"
---

# 5 lessons learned applying 'Smart Integration' in AI/ML development.
---
<br><br>
# **Under Construction**
<br><br>
In April 2022, Silvio Palumbo wrote a <a target="_blank" rel="noopener noreferrer" href="https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614">blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI/ML** strategy. The Smart Integration playbook is tailored to companies vying to rise to the cream of the crop in the business of applying AI. And, if your business is looking to embrace AI, the Smart Integration ideas are relevant to your executives, engineers, managers, and, yes, just about everybody else too. 
<br><br>
* ** Definitions: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for certain predictive tasks. These include predicting the next word in a text, recognizing hate speech or misinformation online, translating between languages, etc., the list of use-cases is steadily growing. Here, we will refer to AI and ML, or AI/ML, interchangeably and synonymously.  
<br><br>
As Palumbo puts it, the Smart Integrator find “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.” 
<br><br>
Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.
<br><br>
What differentiates MAMAA/FAANG from the Smart Integrators? The Googles of the world – along with Academia (think UC Berkeley or MIT) – represent the primary researchers. They are responsible for developing the innovative tools that power today’s AI technologies. Fortuitously, many of these tools are open-sourced (such as Apache Spark, Airflow, PyTorch) or productized as services (such as AWS, Databricks, Snowflake), ripe for integration in your organization. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to apply in commercial use-cases. 
<br><br>
In a tooling-enabled world, integrating AI well in commercial settings largely comes down to the communication and execution of the right strategy, one with sound “Smart Integration” fundamentals. Here are a few lessons I’ve learned so far as a data scientist applying these ideas to develop AI/ML products for commercial use-cases. 
<br><br>

## Lesson 1: Prioritize use-cases [that can easily] deliver value to the most people

---
<br><br>

You don't want to get trapped searching for use-cases where the primary value proposition is how proprietary your models could be. Google will always beat your organization's model in the end, what is far more important is finding the workstreams that can seamlessly plug into the AI solution, regardless if your model is 87 or 93 percent accurate. 

<br><br>
## Lesson 2: Spread the “multi-disciplinary” mantra to every level of your team
---
<br><br>
## Lesson 3: Evolve in waves with a culture of experimentation
---
<br><br>
## Lesson 4: Build trusted products 
---
<br><br>
## Lesson 5: Focus on great user experiences
---
<br><br>
Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience.
<br><br>
