---
title: "5 lessons learned applying 'Smart Integration' in AI/ML development."
date: 2022-08-10
katex: true
markup: "mmark"
---

# 5 lessons learned applying 'Smart Integration' in AI/ML development.
---
<br><br>
# **Under Construction**
<br><br>
In April 2022, Silvio Palumbo wrote a <a target="_blank" rel="noopener noreferrer" href="https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614">blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI/ML** strategy. The Smart Integration playbook is tailored to companies vying to rise to the cream of the crop in the business of applying AI. And, if your business is looking to embrace AI, the Smart Integration ideas are relevant to your executives, engineers, managers, and, yes, just about everybody else too. 
<br><br>
* ** Definitions: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for certain predictive tasks. These include predicting the next word in a text, recognizing hate speech or misinformation online, translating between languages, etc., the list of use-cases is steadily growing. Here, we will refer to AI and ML, or AI/ML, interchangeably and synonymously.  
<br><br>
As Palumbo puts it, the Smart Integrator finds “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.” 
<br><br>
Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.
<br><br>
What differentiates MAMAA/FAANG from the Smart Integrators? The Googles of the world – along with Academia (think UC Berkeley or MIT) – represent primary research players. They are responsible for developing the innovative tools that power today’s AI technologies. Fortuitously, many of these tools are open-sourced (such as Apache Spark, Airflow, PyTorch) or productized as services (such as AWS, Databricks, Snowflake), ripe for integration in your organization. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to apply. 
<br><br>
In a tooling-enabled world, integrating AI well in commercial use-cases largely comes down to the communication and execution of the "Smart Integration" strategy. Here are a few lessons I’ve learned applying these ideas to develop AI/ML solutions that people love. 
<br><br>

## Lesson 1: Prioritize use-cases that can easily deliver value 

---
<br><br>
AI solutions can yield outsized returns for your business – when models are working for you. AI is working for you when it's delivering value to the most people. Machine learning models should be automating tasks, augmenting workstreams, or otherwise creating value. If sitting ideal in research mode, they aren't of much use to your digital transformation. 

A key difference between integrating AI versus innovating in AI is that your commercial model only needs to be performant enough to the given threshold of product "success", no higher. If it is, get it into production, and start squeezing value! 

Go for tools that are more “low-hanging fruit” instead of “next-generation”, both in terms of commercial applicability and in terms of technical viability. You don't want to get trapped developing for use-cases where the primary value proposition is how proprietary or accurate a model could be. The magic sauce isn’t the model’s accuracy score. It’s about the commercial value of the product. For example, if you're crafting a tool that augments an analysis workstream, it may not matter so much whether your model is 92% or 94% accurate. What matters is whether or not it's able to be plugged into your workstream to mine greenfield insights (or not). That’s not to say model accuracy doesn’t matter. You also don't want to get trapped developing models for unproven use-cases, where reaching the requisite performance threshold is difficult. In short, users’ “first awesome experience” should not be tarnished by models that have noticeably poor-quality predictions. 

Another key to use-case scoping is finding ideas that can permeate across your company's different workstreams. A product that can deliver value for more engagements is working for more people in your organization. The most valuable tools are the often ones that have the potential to generalize across your business functions. But it’s not simply about finding a diversity of plug-ins. Does your business do 150 deals of workstream A, and an AI tool can deliver greenfield value to each engagement? Probably a better avenue to pursue than a product that is only relevant to workstreams B, C, and D that would perhaps go unused because those particular workstreams didn’t occur as much as workstream A. In short, it pays to be careful when scoping commercial value and viability.

<br><br>
## Lesson 2: Spread the “multi-disciplinary” mantra to every level of your team
---
<br><br>
## Lesson 3: Evolve in waves with a culture of experimentation
---
<br><br>
## Lesson 4: Build trusted products 
---
<br><br>
## Lesson 5: Focus on great user experiences
---
<br><br>
Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience.
<br><br>
