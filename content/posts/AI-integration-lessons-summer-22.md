---
title: "4 lessons learned applying 'Smart Integration' in AI development."
date: 2022-08-10
katex: true
markup: "mmark"
---

# 4 lessons learned applying 'Smart Integration' in AI development.
---
<br><br>
# **Under Construction**
<br><br>
In April 2022, Silvio Palumbo wrote a <a target="_blank" rel="noopener noreferrer" href="https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614">blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI ** strategy. The Smart Integration strategy is tailored to companies vying to become the cream of the crop in the business of applying AI. 
<br><br>
As Palumbo puts it, the Smart Integrator finds “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.” 
<br><br>
Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.
<br><br>
What differentiates MAMAA/FAANG from the Smart Integrators? The Googles of the world – along with Academia (think UC Berkeley or MIT) – are primary research players. They are responsible for developing innovative tools that power AI technologies. Fortuitously, many of these tools are open-sourced (such as Apache Spark, Airflow, PyTorch) or productized as services (such as AWS, Databricks, Snowflake), ripe for integration in your organization. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to apply. 
<br><br>
In a tooling-enabled world, integrating AI well in commercial use-cases largely comes down to the communication and execution of the right strategy. Here are a few lessons I’ve learned applying Smart Integration to develop AI solutions that people love.
<br><br>
* ** Definitions: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for certain predictive tasks. These include predicting the next word in a text, recommending friends on a social media platform, recognizing hate speech or misinformation online, translating between languages, etc., the list of use-cases is steadily growing. Here, we will refer to AI and ML interchangeably and synonymously. Often they are combined: AI/ML.


## Lesson 1: On scoping use-cases: Know when AI is right (or wrong) pre-development

---
<br><br>
AI is working for your business when it's plugged into commercial use-cases and generating value. Machine learning models should be actively automating tasks, augmenting analyses, surfacing information, or be otherwise engaged. If models are sitting idle, you’re not quite there yet. And, frequently, the reason the models are sitting idle is because AI wasn’t right for the given use-case (Cassie K., steps to an AI project).
<br><br>
It pays to be methodical when scoping the commercial value and viability of an AI solution. Incorporate all voices across your team throughout the scoping phase. Communicate your high-level AI strategies across the team.
<br><br>
With the right use-case, integrating AI into a tool that people love (and use) becomes far more straightforward. Go for options that are more “low-hanging fruit” at first, both in terms of commercial applicability and technical viability. You don't want users’ “first awesome experience” of a product to be tarnished by poor-quality predictions. By going with a “low-hanging fruit”, you’re guaranteeing that the model can reach the “product success” threshold without too much fuss, and you are freed to think diligently about how to best plug in the tool into your commercial use-cases. 
<br><br>
Look for AI solutions that can deliver the most value (sounds obvious, right?). Eyeing the opportunities with high-value propositions is more important than trying to build “cool” products. Does your business do 150 deals of workstream A, and an AI tool can deliver greenfield value to each engagement? Oh, and perhaps we can plug it into workstreams B and C as well? Probably a good avenue to pursue development for. It’s certainly a better avenue to pursue compared with a “cooler”  tool that is tailored specifically to workstream D, which occurs less frequently than the other workstreams. Yes, this holds true despite whether or not there’s a difference in the IP value of the underlying machine learning models. Better to go with a tool that plugs in well across your business’s engagements than a tool that is more of a fancy research project.
<br><br>
## Lesson 2: On ideating solutions: AI and data analytics pair well
In lieu of fully automatable workstreams, aim to augment existing analytics with alternative data and machine learning. Data quality over data quantity, most of the time
## Lesson 3: On team structure: Spread the “multi-disciplinary” mantra to every dimension of your project
---
<br><br>
## Lesson 4: On product development: Focus on great user experiences
---
<br><br>
Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience.
<br><br>
Build trusted products
![image](https://user-images.githubusercontent.com/67394384/184272416-7ea3b8c2-0609-4d06-af49-1f9763991600.png)
