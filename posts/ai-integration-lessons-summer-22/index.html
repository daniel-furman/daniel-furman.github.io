<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>5 lessons learned applying 'Smart Integration' in AI/ML development.</title><meta name=description content="Daniel Furman's Portfolio and Blog"><meta name=author content="Daniel Furman"><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=/sass/researcher.min.css><link rel=icon type=image/ico href=https://daniel-furman.github.io/favicon.ico></head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})</script><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a class="navbar-brand mx-0 mr-sm-auto" href=https://daniel-furman.github.io/>Daniel Furman</a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=/>About</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/posts>Posts</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/bookshelf>Bookshelf</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/resume>Resume</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/contact>Contact</a></div></nav></div><hr><div id=content><div class=container><h1 id=5-lessons-learned-applying-smart-integration-in-aiml-development>5 lessons learned applying &lsquo;Smart Integration&rsquo; in AI/ML development.</h1><hr><p><br><br></p><h1 id=under-construction><strong>Under Construction</strong></h1><p><br><br>In April 2022, Silvio Palumbo wrote a <a target=_blank rel="noopener noreferrer" href=https://medium.com/bcggamma/smart-integration-four-levels-of-ai-maturity-and-why-its-ok-to-be-at-level-3-2af0c94c9614>blog</a> about “Smart Integration” – a playbook of sorts on how to nail commercial AI/ML** strategy. The Smart Integration playbook is tailored to companies vying to rise to the cream of the crop in the business of applying AI. And, if your business is looking to embrace AI, the Smart Integration ideas are relevant to your executives, engineers, managers, and, yes, just about everybody else too.<br><br></p><ul><li>** Definitions: AI refers to Artificial Intelligence, a sub-field of computer science and data science that concerns the crafting of machine learning (ML) models for certain predictive tasks. These include predicting the next word in a text, recognizing hate speech or misinformation online, translating between languages, etc., the list of use-cases is steadily growing. Here, we will refer to AI and ML, or AI/ML, interchangeably and synonymously.<br><br><br>As Palumbo puts it, the Smart Integrator finds “competitive advantage by orchestrating tools and AI applications that have been developed by other specialized organizations, and then directing the tools to fit their specific data, technology, and talent context.”<br><br>Basically, everyone outside of MAMAA/FAANG should strive to be a Smart Integrator.<br><br>What differentiates MAMAA/FAANG from the Smart Integrators? The Googles of the world – along with Academia (think UC Berkeley or MIT) – are primary research players. They are responsible for developing innovative tools that power AI technologies. Fortuitously, many of these tools are open-sourced (such as Apache Spark, Airflow, PyTorch) or productized as services (such as AWS, Databricks, Snowflake), ripe for integration in your organization. And, over the last five to ten years, such tools have become far more performant, scalable, diversified, and economical to apply.<br><br>In a tooling-enabled world, integrating AI well in commercial use-cases largely comes down to the communication and execution of the right strategy. Here are a few lessons I’ve learned applying Smart Integration ideas to develop AI/ML solutions that people use.<br><br></li></ul><h2 id=lesson-1-prioritize-use-cases-not-models>Lesson 1: Prioritize use-cases, not models</h2><hr><p><br><br>AI solutions can yield outsized returns, yes – when models are in deployment. AI is working for you when it&rsquo;s plugged into workstreams. AI models should be automating tasks, augmenting analyses, or otherwise creating value. If sitting ideal in research mode, you’re not quite there yet.<br><br>Luckily, it’s easier to integrate solutions than innovate them. A key difference between integrating AI versus innovating is that your commercial solution only needs to be performant enough to the given threshold of product &ldquo;success&rdquo;, and no higher. And, for commercial products, there indeed can be multiple dimensions to product success. Accuracy, latency, trustworthiness, etc. If it is performant enough along all of the relevant dimensions, get the model into production, and start squeezing value out of it! If it isn&rsquo;t performant enough, don&rsquo;t roll it out. While seemingly simple guidelines, it can be difficult to pinpoint where &ldquo;performant enough&rdquo; lies for the given situation.<br><br>Given these rules, at first, go for tools that are more “low-hanging fruit” over “next-generation”, both in terms of commercial applicability and technical viability. You don&rsquo;t want to get trapped developing for use-cases where the primary value proposition is how proprietary a model could be. The magic sauce isn’t the model’s accuracy score. Integrating AI is about the value of plugging a model into a given application. For example, if you&rsquo;re crafting a tool that augments an analytics workstream, it may not matter so much whether your model is 87%, 92% or 94% accurate in production. What matters is whether or not the modeling outputs can be plugged in to generate greenfield insights for the analysis (or not). That’s not to say model accuracy doesn’t matter. You don&rsquo;t want to start developing models for unproven use-cases where reaching the requisite performance threshold is likely to be difficult. In short, users’ “first awesome experience” should not be tarnished by models that have noticeably poor-quality predictions.<br><br>Another key to use-case scoping is finding ideas that can permeate across your company&rsquo;s different workstreams. A product that can deliver value for more engagements is working for more people in your organization. The most valuable tools are the often ones that have the potential to generalize across your business functions. But it’s not simply about finding a diversity of plug-ins. Does your business do 150 deals of workstream A, and an AI tool can deliver greenfield value to each engagement? Probably a better avenue to pursue than a product that is only relevant to workstreams B, C, and D that would perhaps go unused because those particular workstreams didn’t occur as much as workstream A. In short, it pays to be careful when scoping commercial value and viability.<br><br></p><h2 id=lesson-2-spread-the-multi-disciplinary-mantra-to-every-level-of-your-team>Lesson 2: Spread the “multi-disciplinary” mantra to every level of your team</h2><hr><p><br><br></p><h2 id=lesson-3-evolve-in-waves-with-a-culture-of-experimentation>Lesson 3: Evolve in waves with a culture of experimentation</h2><hr><p><br><br></p><h2 id=lesson-4-build-trusted-products>Lesson 4: Build trusted products</h2><hr><p><br><br></p><h2 id=lesson-5-focus-on-great-user-experiences>Lesson 5: Focus on great user experiences</h2><hr><p><br><br>Even at the v0 prototype stage, make sure to share your “final product” vision with beta users. And, for your v0 product, ensure enough energy and attention were given to the user experience.<br><br></p></div></div><html><body><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://daniel-furman.github.io/><small>By Daniel Furman</small></a></div></div></body><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css integrity=sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js integrity=sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O crossorigin=anonymous></script></html></body></html>