<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Text clustering: HDBSCAN is probably all you need.</title><meta name=description content="Daniel Furman's Portfolio and Blog"><meta name=author content="Daniel Furman"><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=/sass/researcher.min.css><link rel=icon type=image/ico href=https://daniel-furman.github.io/favicon.ico></head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})</script><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a class="navbar-brand mx-0 mr-sm-auto" href=https://daniel-furman.github.io/>Daniel Furman</a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=/>About</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/posts>Posts</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/bookshelf>Bookshelf</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/resume>Resume</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/contact>Contact</a></div></nav></div><hr><div id=content><div class=container><h1 id=text-clustering-hdbscan-is-probably-all-you-need>Text clustering: HDBSCAN is probably all you need</h1><hr><p>Post corresponds to the README from this <a href=https://github.com/daniel-furman/awesome-chatgpt-prompts-clustering>repo</a>.</p><hr><h2 id=goal>Goal</h2><p>Segment common items in a text dataset to pinpoint core themes and their distribution.</p><ul><li>Clusters cover the main topics/subtopics in the dataset</li><li>Clusters backed by <a href=https://platform.openai.com/docs/models/gpt-3-5>gpt-3.5-turbo-16k</a> generated summaries</li></ul><h2 id=background>Background</h2><p>We employ <a href=https://hdbscan.readthedocs.io/en/latest/index.html>HDBSCAN</a> for probabilistic clustering. This algorithm is advantageous in many ways, including:</p><ul><li>Don’t be wrong: Cluster can have varying densities, don’t need to be globular, and won’t include noise</li><li>Intuitive parameters: Choosing a minimum cluster size is very reasonable, and the number of <em>k</em> clusters does not need to be specified (HDBSCAN finds the optimal <em>k</em> for you)</li><li>Stability: HDBSCAN is stable over runs and subsampling and has good stability over parameter choices</li><li>Performance: When implemented well HDBSCAN can be very efficient; the current implementation has similar performance to fastcluster’s agglomerative clustering</li></ul><h2 id=citations>Citations</h2><ul><li>Datasets<ul><li><a href=https://huggingface.co/datasets/fka/awesome-chatgpt-prompts>fka/awesome-chatgpt-prompts</a></li><li><a href=https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts>gustavosta/stable-diffusion-prompts</a></li></ul></li><li>Embedding models<ul><li><a href=https://huggingface.co/sentence-transformers/all-mpnet-base-v2>sentence-transformers/all-mpnet-base-v2</a></li></ul></li></ul><h2 id=experiments>Experiments</h2><br><h3 id=1-visualizing-core-themes-in-fkaawesome-chatgpt-promptshttpshuggingfacecodatasetsfkaawesome-chatgpt-prompts>1. Visualizing core themes in <a href=https://huggingface.co/datasets/fka/awesome-chatgpt-prompts>fka/awesome-chatgpt-prompts</a></h3><p>These figures correspond to <a href=https://github.com/daniel-furman/awesome-chatgpt-prompts-clustering/tree/main/experiments/02_09_2023_16_54_32><code>experiments/02_09_2023_16_54_32</code></a></p><h3 id=clustering>Clustering</h3><p><img src=/posts/hdbscan-assets//clusters_viz_1.png alt></p><p><strong>Figure 1</strong>. The clustering algorith splits the data into three segments, &ldquo;cluster 0&rdquo; with 44 prompts (orange), &ldquo;cluster 1&rdquo; with 105 prompts (blue), and &ldquo;outliers&rdquo; with 4 prompts (gray). See the HDBSCAN docs on <a href=https://hdbscan.readthedocs.io/en/latest/comparing_clustering_algorithms.html#hdbscan>comparing clustering algorithms</a> and <a href=https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html>how hdbscan works</a> for more information.</p><h3 id=exemplars>Exemplars</h3><p><img src=/posts/hdbscan-assets//exemplars_viz_1.png alt></p><p><strong>Figure 2</strong>. The most persistent prompts in each leaf cluster are known as &ldquo;exemplars&rdquo;. These represent the hearts around which the ultimate cluster formed. See the HDBSCAN docs on <a href=https://hdbscan.readthedocs.io/en/latest/soft_clustering_explanation.html#distance-based-membership>soft clustering explanation</a> for supporting information and functions.</p><h3 id=sub-clustering>Sub-Clustering</h3><p><img src=/posts/hdbscan-assets//exemplars_viz_2.png alt></p><p><strong>Figure 3</strong>. Additional clustering is conducted around the exemplars to identify sub-topics in the dataset. The cases in each sub-cluster then serve as context for the <a href=https://platform.openai.com/docs/models/gpt-3-5>gpt-3.5-turbo-16k</a> calls below.</p><h3 id=themes-summarization>Themes Summarization</h3><p><img src=/posts/hdbscan-assets//cluster0_subcluster0.png alt>
<img src=/posts/hdbscan-assets//cluster0_subcluster1.png alt>
<img src=/posts/hdbscan-assets//cluster1_subcluster2.png alt>
<img src=/posts/hdbscan-assets//cluster1_subcluster3.png alt>
<img src=/posts/hdbscan-assets//cluster1_subcluster4.png alt>
<img src=/posts/hdbscan-assets//cluster1_subcluster5.png alt></p><p><strong>Figure 4</strong>. A visualization of the dataset&rsquo;s core themes, which were generated by <a href=https://platform.openai.com/docs/models/gpt-3-5>gpt-3.5-turbo-16k</a>. The above was created with <a href=https://jsoncrack.com/editor>jsoncrack.com/editor</a>.</p><br><h3 id=2-drift-detection-for-gustavostastable-diffusion-promptshttpshuggingfacecodatasetsgustavostastable-diffusion-prompts>2. Drift detection for <a href=https://huggingface.co/datasets/Gustavosta/Stable-Diffusion-Prompts>gustavosta/stable-diffusion-prompts</a></h3><p><strong>Coming</strong></p></div></div><html><body><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://daniel-furman.github.io/><small>By Daniel Furman</small></a></div></div></body><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css integrity=sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js integrity=sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O crossorigin=anonymous></script></html></body></html>