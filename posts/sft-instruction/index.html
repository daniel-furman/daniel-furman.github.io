<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Supervised finetuning of instruction-following LLMs</title><meta name=description content="Daniel Furman's Portfolio and Blog"><meta name=author content="Daniel Furman"><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=/sass/researcher.min.css><link rel=icon type=image/ico href=https://daniel-furman.github.io/favicon.ico></head><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})})</script><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a class="navbar-brand mx-0 mr-sm-auto" href=https://daniel-furman.github.io/>Daniel Furman</a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=/>About</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/posts>Posts</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/bookshelf>Bookshelf</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/resume>Resume</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/contact>Contact</a></div></nav></div><hr><div id=content><div class=container><h1 id=supervised-finetuning-of-instruction-llms>Supervised finetuning of instruction LLMs</h1><hr><p>Post corresponds to the README from this <a href=https://github.com/daniel-furman/sft-demos>repo</a>.</p><hr><p>This repo contains demos for supervised finetuning (sft) of large language models, like Meta&rsquo;s <a href=https://huggingface.co/meta-llama/Llama-2-7b-hf>llama-2</a>. In particular, we focus on tuning for short-form instruction following capabilities.</p><h2 id=table-of-contents>Table of contents</h2><ol><li><a href=https://github.com/daniel-furman/sft-demos#instruction-tuning-background>Instruction tuning background</a></li><li><a href=https://github.com/daniel-furman/sft-demos#code-assets>Code assets</a></li><li><a href=https://github.com/daniel-furman/sft-demos#base-models-and-datasets>Base models and datasets</a></li><li><a href=https://github.com/daniel-furman/sft-demos#finetuned-models>Finetuned models</a></li><li><a href=https://github.com/daniel-furman/sft-demos#basic-usage-of-peft-models>Basic usage of peft models</a></li></ol><hr><h2 id=instruction-tuning-background>Instruction tuning background</h2><p>In recent years, there has been a growing interest in building models that can follow natural language instructions to perform a wide range of tasks. These models, known as &ldquo;instruction-tuned&rdquo; language models, have demonstrated the ability to generalize to new tasks.</p><p>The below was captured from the &ldquo;<a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">State of GPTs</a>&rdquo; talk by Andrej Karpathy. The key points illustrated for SFT:</p><ul><li>Collect small but high-quality datasets in the form of &ldquo;prompt&rdquo; and &ldquo;ideal responses&rdquo;.</li><li>Do language modeling on this data, nothing changes algorithmically from pretraining.</li><li>After training we get an SFT model which can be deployed as assistants (and it works to some extent).</li></ul><p><img src=/posts/sft-assets/assistant_training_pipeline.png alt=training_pipeline></p><p>For more background, see any number of excellent papers on the subject, including <a href=https://arxiv.org/pdf/2212.10560.pdf>Self-Instruct</a> (2023), <a href=https://arxiv.org/pdf/2306.02707.pdf>Orca</a> (2023), and <a href=https://arxiv.org/pdf/2203.02155.pdf>InstructGPT</a> (2022).</p><h2 id=code-assets>Code assets</h2><ul><li>See the <code>./sft</code> folder for finetuning scripts and postprocessing notebooks.</li><li>See the <code>./runs</code> folder for the raw results from each sft experiment.</li><li>See the <code>./inf_tests</code> folder for runtime testing notebooks.</li></ul><h2 id=base-models-and-datasets>Base models and datasets</h2><p>In this repo, we finetune the following base models. Each is open-source and licensed for commercial use.</p><ul><li><a href=https://huggingface.co/meta-llama/Llama-2-70b-hf>llama-2</a></li><li><a href=https://huggingface.co/tiiuae/falcon-180B>falcon</a></li><li><a href=https://huggingface.co/mosaicml/mpt-7b>mpt</a></li></ul><p>We test the following datasets. Each is open-source and licensed for commercial use.</p><ul><li><a href=https://huggingface.co/datasets/timdettmers/openassistant-guanaco>timdettmers/openassistant-guanaco</a></li><li><a href=https://huggingface.co/datasets/ehartford/dolphin>ehartford/dolphin</a></li><li><a href=https://huggingface.co/datasets/garage-bAInd/Open-Platypus>garage-bAInd/Open-Platypus</a></li></ul><h2 id=finetuned-models>Finetuned models</h2><p><strong>NB</strong>: We use state-of-the-art <a href=https://github.com/EleutherAI/lm-evaluation-harness>Language Model Evaluation Harness</a> to run the benchmark tests below, using the same version as Hugging Face&rsquo;s <a href=https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>Open LLM Leaderboard</a>.</p><br><h2 id=1-falcon-180b-instruct-pefthttpshuggingfacecodfurmanfalcon-180b-instruct-peft>1. <a href=https://huggingface.co/dfurman/falcon-180b-instruct-peft>falcon-180b-instruct-peft</a></h2><ul><li>Dataset(s): 50% ehartford/dolphin & 50% garage-bAInd/Open-Platypus</li></ul><p>This instruction model was built via parameter-efficient QLoRA finetuning of <a href=https://huggingface.co/tiiuae/falcon-180B>falcon-180b</a> on the first 5k rows of <a href=https://huggingface.co/datasets/ehartford/dolphin>ehartford/dolphin</a> and the first 5k riws of <a href=https://huggingface.co/datasets/garage-bAInd/Open-Platypus>garage-bAInd/Open-Platypus</a>. Finetuning was executed on 4x A6000s (48 GB RTX) for roughly 32 hours on the <a href=https://cloud.lambdalabs.com/instances>Lambda Labs</a> platform.</p><h3 id=benchmark-metrics>Benchmark metrics</h3><table><thead><tr><th>Metric</th><th>Value</th></tr></thead><tbody><tr><td>MMLU (5-shot)</td><td>Coming</td></tr><tr><td>ARC (25-shot)</td><td>Coming</td></tr><tr><td>HellaSwag (10-shot)</td><td>Coming</td></tr><tr><td>TruthfulQA (0-shot)</td><td>Coming</td></tr><tr><td>Avg.</td><td>Coming</td></tr></tbody></table><h3 id=helpful-links>Helpful links</h3><ul><li>Model license: <a href=https://huggingface.co/spaces/tiiuae/falcon-180b-license/blob/main/LICENSE.txt>Falcon-180B TII License</a></li><li>Basic usage: <a href=https://github.com/daniel-furman/sft-demos/blob/main/src/sft/multi_gpus/falcon/postprocessing-falcon-180b-instruct-peft.ipynb>here</a></li><li>Finetuning code: <a href=https://github.com/daniel-furman/sft-demos/blob/main/src/sft/multi_gpus/falcon/sft-falcon-180b-instruct-peft.py>here</a></li><li>Runtime stats: <a href=https://github.com/daniel-furman/sft-demos#runtime-tests>here</a></li></ul><h3 id=loss-curve>Loss curve</h3><p><img src=https://raw.githubusercontent.com/daniel-furman/sft-demos/main/assets/sep_12_23_9_20_00_log_loss_curves_falcon-180b-instruct.png alt=loss_curves></p><p>The above loss curve was generated from the run&rsquo;s private wandb.ai log.</p><h3 id=example-prompts-and-responses>Example prompts and responses</h3><p>Example 1:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Write me a numbered list of things to do in New York City.\n</p></blockquote><p><strong>falcon-180b-instruct-peft</strong>:</p><blockquote><ol><li>Visit the Empire State Building: Take in the breathtaking views of the city from the observation deck on the 86th floor.</li><li>Stroll through Central Park: Enjoy the lush greenery, lakes, and various attractions in this iconic urban park.</li><li>Explore the Metropolitan Museum of Art: Admire the vast collection of art from around the world, spanning thousands of years.</li><li>See a Broadway show: Experience the magic of live theater in one of the world&rsquo;s most famous theater districts.</li><li>Walk across the Brooklyn Bridge: Take in the stunning views of the Manhattan skyline and the East River as you cross this iconic bridge.</li><li>Visit the Statue of Liberty: Take a ferry to Liberty Island and climb to the top of the statue for a unique perspective of the city.</li><li>Visit the 9/11 Memorial and Museum: Pay tribute to the victims of the September 11th attacks and learn about the events that changed the world.</li><li>Visit Times Square: Experience the bright lights and bustling energy of this iconic intersection.</li><li>Visit the High Line: Stroll along this elevated park, built on a former railroad track, and &mldr;</li></ol></blockquote><br><p>Example 2:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Write a short email inviting my friends to a dinner party on Friday. Respond succinctly.\n</p></blockquote><p><strong>falcon-180b-instruct-peft</strong>:</p><blockquote><p>Subject: Dinner Party Invitation - Friday, 7pm</p><p>Dear friends,</p><p>I would like to invite you to a dinner party at my place this Friday at 7pm. It would be a great opportunity to catch up and enjoy some delicious food together.</p><p>Please let me know if you can make it by Wednesday. I look forward to seeing you all!</p><p>Best,
[Your Name]</p><p>P.S. Please let me know if you have any dietary restrictions.</p></blockquote><br><p>Example 3:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Tell me a recipe for vegan banana bread.\n</p></blockquote><p><strong>falcon-180b-instruct-peft</strong>:</p><blockquote><p>Ingredients:</p><ul><li>3 ripe bananas</li><li>1/3 cup melted coconut oil or vegan butter</li><li>1/4 cup non-dairy milk (almond, soy, or oat milk)</li><li>1 teaspoon vanilla extract</li><li>1/2 cup brown sugar</li><li>1 1/2 cups all-purpose flour</li><li>1 teaspoon baking powder</li><li>1/2 teaspoon baking soda</li><li>1/2 teaspoon salt</li><li>1/2 teaspoon ground cinnamon (optional)</li><li>1/2 cup chopped walnuts or chocolate chips (optional)</li></ul><p>Instructions:</p><ol><li>Preheat your oven to 350°F (175°C). Grease a 9x5-inch loaf pan with vegan butter or coconut oil.</li><li>In a large mixing bowl, mash the ripe bananas with a fork until they are smooth.</li><li>Add the melted coconut oil or vegan butter, non-dairy milk, vanilla extract, and brown sugar to the mashed bananas. Mix well until combined.</li><li>In a separate bowl, whisk together the all-purpose flour, baking powder, baking soda, salt, and ground cinnamon (if using).</li><li>Gradually add the dry ingredients to the wet ingredients, mixing until just combined. Do not overmix.</li><li>If you&rsquo;re using walnuts or chocolate chips, gently fold them into the batter.</li><li>Pour the batter into the prepared loaf pan and smooth the top with a spatula.</li><li>Bake for 45-55 minutes, or until a toothpick inserted into the center of the loaf comes out clean.</li><li>Allow the banana bread to cool in the pan for 10 minutes before transferring it to a wire rack to cool completely.</li><li>Slice and serve warm or at room temperature. Enjoy!</li></ol><p>Note: You can also use whole wheat flour or a gluten-free flour blend in place of all-purpose flour. Adjust the baking time accordingly, as whole wheat flour or gluten-free flour may require a longer baking time.</p><p>Optional variations:</p><ul><li>Add 1/2 cup of chopped nuts (walnuts, pecans, or almonds) or chocolate chips to the batter for extra flavor and texture.</li></ul></blockquote><br><h3 id=runtime-tests>Runtime tests</h3><table><thead><tr><th style=text-align:center>runtime / 50 tokens (sec)</th><th style=text-align:center>GPU</th><th style=text-align:center>attn</th><th style=text-align:center>torch dtype</th><th style=text-align:center>VRAM (GB)</th></tr></thead><tbody><tr><td style=text-align:center>27.15</td><td style=text-align:center>4x A6000s (48 GB RTX)</td><td style=text-align:center>torch</td><td style=text-align:center>nf4</td><td style=text-align:center>140</td></tr></tbody></table><br><h2 id=2-llama-2-70b-dolphin-pefthttpshuggingfacecodfurmanllama-2-70b-dolphin-peft>2. <a href=https://huggingface.co/dfurman/llama-2-70b-dolphin-peft>llama-2-70b-dolphin-peft</a></h2><ul><li>Dataset(s): 100% ehartford/dolphin</li></ul><p>This instruction model was built via parameter-efficient QLoRA finetuning of <a href=https://huggingface.co/meta-llama/Llama-2-70b-hf>llama-2-70b</a> on the first 25k rows of <a href=https://huggingface.co/datasets/ehartford/dolphin>ehartford/dolphin</a> (an open-source implementation of <a href=https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/>Microsoft&rsquo;s Orca</a>). Finetuning was executed on a single H100 (80 GB PCIe) for roughly 17 hours on the <a href=https://cloud.lambdalabs.com/instances>Lambda Labs</a> platform.</p><h3 id=benchmark-metrics-1>Benchmark metrics</h3><table><thead><tr><th>Metric</th><th>Value</th></tr></thead><tbody><tr><td>MMLU (5-shot)</td><td>69.18</td></tr><tr><td>ARC (25-shot)</td><td>69.62</td></tr><tr><td>HellaSwag (10-shot)</td><td>86.82</td></tr><tr><td>TruthfulQA (0-shot)</td><td>57.43</td></tr><tr><td>Avg.</td><td>70.76</td></tr></tbody></table><h3 id=helpful-links-1>Helpful links</h3><ul><li>Model license: Llama 2 Community License Agreement</li><li>Basic usage: <a href=https://huggingface.co/dfurman/llama-2-70b-dolphin-peft/blob/main/assets/basic_inference_llama_2_70b_dolphin.ipynb>notebook</a></li><li>Finetuning code: <a href=https://github.com/daniel-furman/sft-demos/blob/main/src/sft/one_gpu/llama-2/dolphin/sft-llama-2-70b-dolphin-peft.py>script</a></li></ul><h3 id=loss-curve-1>Loss curve</h3><p><img src=https://raw.githubusercontent.com/daniel-furman/sft-demos/main/assets/jul_24_23_1_14_00_log_loss_curves_llama-2-70b-dolphin.png alt=loss_curves></p><p>The above loss curve was generated from the run&rsquo;s private wandb.ai log.</p><h3 id=example-prompts-and-responses-1>Example prompts and responses</h3><p>Example 1:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Write me a numbered list of things to do in New York City.\n</p></blockquote><p><strong>llama-2-70b-dolphin-peft</strong>:</p><blockquote><ol><li>Visit the Statue of Liberty: Take a ferry to Liberty Island and see the iconic symbol of freedom and democracy.</li><li>Explore Central Park: Enjoy the lush greenery, take a stroll, or rent a bike to explore the park&rsquo;s many attractions, such as the Central Park Zoo and Strawberry Fields.</li><li>Visit the Empire State Building: Take an elevator to the observation deck for breathtaking views of the city.</li><li>Walk the Brooklyn Bridge: Cross the historic bridge and enjoy the stunning views of the Manhattan skyline.</li><li>Experience Times Square: Take in the bright lights, billboards, and bustling energy of this iconic intersection.</li><li>Visit the Metropolitan Museum of Art: Explore the vast collection of art and artifacts from around the world.</li><li>Take a food tour: Sample the diverse cuisine of New York City, from pizza to bagels to ethnic specialties.</li><li>Attend a Broadway show: Enjoy a world-class performance in the heart of the Theater District.</li></ol></blockquote><br><p>Example 2:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Write a short email inviting my friends to a dinner party on Friday. Respond succinctly.\n</p></blockquote><p><strong>llama-2-70b-dolphin-peft</strong>:</p><blockquote><p>Subject: Dinner Party Invitation - Friday, 7 PM</p><p>Dear Friends,</p><p>I hope this email finds you well! I&rsquo;m excited to invite you to a dinner party at my place this Friday, at 7 PM. We&rsquo;ll have a delicious meal, great company, and lots of fun. Please let me know if you can make it, so I can plan accordingly.</p><p>Looking forward to seeing you all!</p><p>Kind regards,
Your Name</p></blockquote><blockquote><p>P.S. Please let me know if you have any dietary restrictions or allergies.</p></blockquote><br><p>Example 3:</p><p><strong>User</strong>:</p><blockquote><p>You are a helpful assistant. Tell me a recipe for vegan banana bread.\n</p></blockquote><p><strong>llama-2-70b-dolphin-peft</strong>:</p><blockquote><p>Sure! Here&rsquo;s a delicious and easy vegan banana bread recipe:</p><p>Ingredients:</p><ul><li>2 cups all-purpose flour</li><li>1/2 cup sugar</li><li>1/2 cup vegan butter (such as Earth Balance)</li><li>1/2 cup vegan milk (such as almond milk)</li><li>1/2 cup unsweetened applesauce</li><li>1/2 cup mashed ripe bananas (about 2 medium bananas)</li><li>1 teaspoon baking soda</li><li>1/2 teaspoon salt</li><li>1/2 teaspoon ground cinnamon</li><li>1/2 teaspoon ground nutmeg</li><li>1/2 teaspoon ground cloves</li><li>1/2 cup chopped walnuts (optional)</li></ul><p>Instructions:</p><ol><li>Preheat the oven to 350°F (175°C). Grease a 9x5-inch loaf pan with vegan butter or cooking spray.</li><li>In a large bowl, mix together the flour, sugar, vegan butter, vegan milk, applesauce, bananas, baking soda, salt, cinnamon, nutmeg, and cloves. Stir until well combined.</li><li>Fold in the chopped walnuts, if using.</li><li>Pour the batter into the prepared loaf pan.</li><li>Bake for 50-60 minutes, or until a toothpick inserted into the center of the bread comes out clean.</li><li>Let the bread cool in the pan for 10 minutes before transferring it to a wire rack to cool completely.</li><li>Slice and enjoy!</li></ol><p>Note: You can also add chocolate chips, dried fruit, or other mix-ins to the batter for extra flavor and texture. Enjoy your vegan banana bread!</p></blockquote><br><h3 id=runtime-tests-1>Runtime tests</h3><table><thead><tr><th style=text-align:center>runtime / 50 tokens (sec)</th><th style=text-align:center>GPU</th><th style=text-align:center>attn</th><th style=text-align:center>torch dtype</th><th style=text-align:center>VRAM (GB)</th></tr></thead><tbody><tr><td style=text-align:center>4.50</td><td style=text-align:center>1x H100 (80 GB PCIe)</td><td style=text-align:center>torch</td><td style=text-align:center>nf4</td><td style=text-align:center>39</td></tr></tbody></table><br><h2 id=basic-usage-of-peft-models>Basic usage of peft models</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>U</span> <span class=n>huggingface_hub</span> <span class=n>peft</span> <span class=n>transformers</span> <span class=n>torch</span> <span class=n>accelerate</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>notebook_login</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>PeftModel</span><span class=p>,</span> <span class=n>PeftConfig</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>AutoModelForCausalLM</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>AutoTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>BitsAndBytesConfig</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>pipeline</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>notebook_login</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>peft_model_id</span> <span class=o>=</span> <span class=s2>&#34;dfurman/falcon-180b-instruct-peft&#34;</span>
</span></span><span class=line><span class=cl><span class=n>config</span> <span class=o>=</span> <span class=n>PeftConfig</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>peft_model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>bnb_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_quant_type</span><span class=o>=</span><span class=s2>&#34;nf4&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>config</span><span class=o>.</span><span class=n>base_model_name_or_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>quantization_config</span><span class=o>=</span><span class=n>bnb_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>use_auth_token</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>config</span><span class=o>.</span><span class=n>base_model_name_or_path</span><span class=p>,</span> <span class=n>use_fast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>PeftModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>peft_model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>format_template</span> <span class=o>=</span> <span class=s2>&#34;You are a helpful assistant. </span><span class=si>{query}</span><span class=se>\n</span><span class=s2>&#34;</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># First, format the prompt</span>
</span></span><span class=line><span class=cl><span class=n>query</span> <span class=o>=</span> <span class=s2>&#34;Tell me a recipe for vegan banana bread.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=n>format_template</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>query</span><span class=o>=</span><span class=n>query</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Inference can be done using model.generate</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>*** Generate:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>input_ids</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>prompt</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>autocast</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span><span class=o>=</span><span class=n>input_ids</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_dict_in_generate</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>eos_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>pad_token_id</span><span class=o>=</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>repetition_penalty</span><span class=o>=</span><span class=mf>1.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=s2>&#34;sequences&#34;</span><span class=p>][</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div></div></div><html><body><div id=footer class=mb-5><hr><div class="container text-center"><a href=https://daniel-furman.github.io/><small>By Daniel Furman</small></a></div></div></body><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css integrity=sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js integrity=sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O crossorigin=anonymous></script></html></body></html>